{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "313ac5ef",
   "metadata": {},
   "source": [
    "### AI KEY 를 통해 LLM 에 프롬프트 수행 샘플\n",
    "- 로컬의 .env 환경 변수를 로드\n",
    "- API Key 를 읽어 LLM 에 프롬프트 수행\n",
    "- 프로그램 개요\n",
    "1.\t파이썬 코드 실행 시\n",
    "\t•\tLangChain의 체인 객체(ChatGoogleGenerativeAI)가 생성되면\n",
    "\t•\t내부적으로 os.environ에서 위 환경변수 값들을 읽음\n",
    "2.\tLLM 호출(예: llm.invoke(question))\n",
    "\t•\tLangChain의 각 체인·프롬프트·콜러블 객체가 자동으로 데코레이팅/후킹되어\n",
    "\t•\t입력 데이터, 프롬프트, LLM 호출 파라미터, 응답 결과, 실행 시간, 예외 등을 내부 캐처에 기록\n",
    "3.\tLangSmith API로 데이터 전송\n",
    "\t•\t위에서 수집된 트레이싱 정보를 LangSmith 서버에 REST API로 비동기 전송\n",
    "\t•\t이 과정은 비즈니스 로직과 분리되어 응답 속도 저하 없이 처리됨\n",
    "4.\tLangSmith 대시보드에서 실시간 관측 가능\n",
    "\t•\t대시보드에 접속하면 실행 내역, LLM 응답, 토큰 사용량, 에러, 체인 흐름 등을 시각적으로 분석 가능\n",
    "\t•\tLANGSMITH_PROJECT 단위로 통계 및 분석 지원"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4977da05",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf54b97a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d18686",
   "metadata": {},
   "source": [
    "\n",
    "- llm 초기화\n",
    "- llm 실행\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5ee2eb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "? 질문: 한국의 수도는 어디인가요?\n",
      "----------------------------------------\n",
      " Gemini 답변: 한국의 수도는 **서울**입니다.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "if not api_key:\n",
    "    print(\".env 파일에 GOOGLE_API_KEY 를 설정해주세요\")\n",
    "    \n",
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-flash\",\n",
    "    google_api_key=api_key,\n",
    "    temperature=0.2\n",
    ")\n",
    "\n",
    "question = \"한국의 수도는 어디인가요?\"\n",
    "print(f\"? 질문: {question}\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "response = llm.invoke(question)\n",
    "print(f\" Gemini 답변: {response.content}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73eb7c7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "71b549fb",
   "metadata": {},
   "source": [
    "- LangSMITH 사이트에서 LLM API 호출, 중간 체인 처리 등을 자동으로 추적 기록하여 요청/응답 데이터, 파라미터, 처리흐름, 오류 등을 대시 보드에서 시각화 할수 있는 기능\n",
    "https://smith.langchain.com/\n",
    "- 로그인 \n",
    "- tracing 정보 확인 할수 있음\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdcef176",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-lecture-8YS9sgva-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
